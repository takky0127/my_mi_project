{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95edb552",
   "metadata": {},
   "source": [
    "# モデル学習を行う際の関数一覧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a6c70",
   "metadata": {},
   "source": [
    "・lightGBM  \n",
    "・RandomForest  \n",
    "・CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c793c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1330694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light GBM(early stopping)\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmsle\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 16,\n",
    "    \"n_estimators\": 100000,\n",
    "    \"importance_type\": \"gain\",\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "def LGBM_cv(input_x, input_y, params, n_split=5):\n",
    "\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    models = []\n",
    "    oof_preds = np.zeros(len(input_x))\n",
    "\n",
    "    cv = list(KFold(n_splits=n_split, shuffle=True, random_state=42).split(input_x, input_y))\n",
    "\n",
    "    for nfold in range(n_split):\n",
    "        print(\"-\" * 20, f\"Fold {nfold}\", \"-\" * 20)\n",
    "        idx_tr, idx_va = cv[nfold]\n",
    "        X_tr, y_tr = input_x.iloc[idx_tr], input_y.iloc[idx_tr]\n",
    "        X_va, y_va = input_x.iloc[idx_va], input_y.iloc[idx_va]\n",
    "\n",
    "        print(X_tr.shape, y_tr.shape)\n",
    "        print(X_va.shape, y_va.shape)\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_tr, y_tr,\n",
    "                  eval_set=[(X_tr, y_tr), (X_va, y_va)],\n",
    "                  eval_metric=\"rmse\",\n",
    "                  callbacks=[\n",
    "                      lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
    "                      lgb.log_evaluation(100)\n",
    "                  ])\n",
    "        models.append(model)\n",
    "\n",
    "        y_tr_pred = model.predict(X_tr)\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        metric_train = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "        metric_test = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "        metrics.append([nfold, metric_train, metric_test])\n",
    "        \n",
    "        oof_preds[idx_va] = y_va_pred\n",
    "\n",
    "        _imp = pd.DataFrame({\n",
    "            \"col\": X_tr.columns,\n",
    "            \"imp\": model.booster_.feature_importance(importance_type='gain'),\n",
    "            \"nfold\": nfold\n",
    "        })\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=True)\n",
    "\n",
    "    print(\"=\" * 20, \"CV Results\", \"=\" * 20)\n",
    "\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print(f\"[cv] train: {metrics[:,1].mean():.5f}±{metrics[:,1].std():.5f}, \"\n",
    "          f\"test: {metrics[:,2].mean():.5f}±{metrics[:,2].std():.5f}\")\n",
    "\n",
    "    imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "    imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "    \n",
    "    # modelsを保存\n",
    "    # joblib.dump(models, \"lgbm_models.pkl\")\n",
    "\n",
    "    return models, imp, metrics, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat_boost (early stopping)\n",
    "cat_params = {\n",
    "    \"iterations\": 1000,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"l2_leaf_reg\": 3.0, \n",
    "    \"verbose\": 100,\n",
    "    \"random_state\": 42\n",
    "    }\n",
    "\n",
    "def cat_cv(input_x, input_y, params, n_split=5):\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    models = []\n",
    "    cat_features = [\"Sex\"]\n",
    "\n",
    "    cv = list(KFold(n_splits=n_split,\n",
    "                              shuffle=True,\n",
    "                              random_state=42).split(input_x, input_y))\n",
    "\n",
    "    for nfold in range(n_split):\n",
    "        print(\"-\" * 20, f\"Fold {nfold}\", \"-\" * 20)\n",
    "        idx_tr, idx_va = cv[nfold][0],cv[nfold][1]\n",
    "        X_tr, y_tr = input_x.iloc[idx_tr], input_y.iloc[idx_tr]\n",
    "        X_va, y_va = input_x.iloc[idx_va], input_y.iloc[idx_va]\n",
    "        print(X_tr.shape, y_tr.shape)\n",
    "        print(X_va.shape, y_va.shape)\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            X_tr,\n",
    "            y_tr,\n",
    "            eval_set=(X_va, y_va),\n",
    "            early_stopping_rounds=50,\n",
    "            use_best_model=True,\n",
    "            cat_features=cat_features,\n",
    "            verbose=100\n",
    "            )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        y_tr_pred = model.predict(X_tr)\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        metric_train = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "        metric_test = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "        metrics.append([nfold, metric_train, metric_test])\n",
    "\n",
    "        _imp = pd.DataFrame({\n",
    "            \"col\": X_tr.columns,\n",
    "            \"imp\": model.get_feature_importance(type='PredictionValuesChange'),\n",
    "            \"nfold\": nfold\n",
    "        })\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=True)\n",
    "\n",
    "    print(\"=\" * 20, \"CV Results\", \"=\" * 20)\n",
    "\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print(f\"[cv] train: {metrics[:,1].mean():.5f}±{metrics[:,1].std():.5f}, \"\n",
    "          f\"test: {metrics[:,2].mean():.5f}±{metrics[:,2].std():.5f}\")\n",
    "\n",
    "    imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "    imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "\n",
    "    return models, imp, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5bdf85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_params = {\"max_depth\": 10,\n",
    "             \"criterion\":\"squared_error\",\n",
    "             \"max_features\":\"sqrt\",\n",
    "             \"min_samples_leaf\": 1,\n",
    "             \"min_samples_split\": 5,\n",
    "             \"n_estimators\": 100,\n",
    "             \"n_jobs\":1,\n",
    "             \"bootstrap\":True,\n",
    "             \"random_state\": 42\n",
    "            }\n",
    "\n",
    "def RF_cv(input_x, input_y, params, n_split=5):\n",
    "\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    models = []\n",
    "\n",
    "    cv = list(KFold(n_splits=n_split, shuffle=True, random_state=42).split(input_x, input_y))\n",
    "\n",
    "    for nfold in range(n_split):\n",
    "        print(\"-\" * 20, f\"Fold {nfold}\", \"-\" * 20)\n",
    "        idx_tr, idx_va = cv[nfold]\n",
    "        X_tr, y_tr = input_x.iloc[idx_tr], input_y.iloc[idx_tr]\n",
    "        X_va, y_va = input_x.iloc[idx_va], input_y.iloc[idx_va]\n",
    "\n",
    "        print(X_tr.shape, y_tr.shape)\n",
    "        print(X_va.shape, y_va.shape)\n",
    "\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_tr, y_tr,)\n",
    "        models.append(model)\n",
    "\n",
    "        y_tr_pred = model.predict(X_tr)\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        metric_train = np.sqrt(mean_squared_error(y_tr, y_tr_pred))\n",
    "        metric_test = np.sqrt(mean_squared_error(y_va, y_va_pred))\n",
    "        metrics.append([nfold, metric_train, metric_test])\n",
    "\n",
    "        _imp = pd.DataFrame({\n",
    "            \"col\": X_tr.columns,\n",
    "            \"imp\": model.feature_importances_,\n",
    "            \"nfold\": nfold\n",
    "        })\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=True)\n",
    "\n",
    "    print(\"=\" * 20, \"CV Results\", \"=\" * 20)\n",
    "\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print(f\"[cv] train: {metrics[:,1].mean():.5f}±{metrics[:,1].std():.5f}, \"\n",
    "          f\"test: {metrics[:,2].mean():.5f}±{metrics[:,2].std():.5f}\")\n",
    "\n",
    "    imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "    imp.columns = [\"col\", \"imp\", \"imp_std\"]\n",
    "\n",
    "    return models, imp, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63757b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rf, imp_rf, metrics_rf = RF_cv(X, y, rf_params)\n",
    "\n",
    "# Feature importanceの表示\n",
    "imp_rf.sort_values(\"imp\", ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d381579",
   "metadata": {},
   "source": [
    "以下、パラメーター設定なし"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e327fa",
   "metadata": {},
   "source": [
    "・CatBoost  \n",
    "・ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bcec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_catboost_cv(input_x, input_y, n=5):\n",
    "    kf = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "    oof_pred = np.zeros(len(input_y))\n",
    "    models = []\n",
    "\n",
    "    importances = np.zeros(input_x.shape[1])\n",
    "    r2_list, mae_list, rmse_list = [], [], []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(input_x):\n",
    "        X_train, X_valid = input_x.iloc[train_idx], input_x.iloc[valid_idx]\n",
    "        y_train, y_valid = input_y.iloc[train_idx], input_y.iloc[valid_idx]\n",
    "\n",
    "        model = CatBoostRegressor(verbose=0, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_valid)\n",
    "        models.append(model)\n",
    "\n",
    "        oof_pred[valid_idx] = pred\n",
    "        importances += model.get_feature_importance()\n",
    "\n",
    "        r2_list.append(r2_score(y_valid, pred))\n",
    "        mae_list.append(mean_absolute_error(y_valid, pred))\n",
    "        rmse_list.append(np.sqrt(mean_squared_error(y_valid, pred)))\n",
    "\n",
    "    # 最終モデルを全データで学習\n",
    "    #final_model = CatBoostRegressor(verbose=0, random_state=42)\n",
    "    #final_model.fit(input_x, input_y)\n",
    "\n",
    "    metric = {\n",
    "        \"R2\": np.mean(r2_list),\n",
    "        \"MAE\": np.mean(mae_list),\n",
    "        \"RMSE\": np.mean(rmse_list)\n",
    "    }\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": input_x.columns,\n",
    "        \"importance\": importances / n\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "    return models, metric, importance_df, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d63340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extratrees_cv(input_x, input_y, n = 5):\n",
    "    kf = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "    oof_pred = np.zeros(len(input_y))\n",
    "\n",
    "    importances = np.zeros(input_x.shape[1])\n",
    "    r2_list, mae_list, rmse_list = [], [], []\n",
    "    models = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(input_x):\n",
    "        X_train, X_valid = input_x.iloc[train_idx], input_x.iloc[valid_idx]\n",
    "        y_train, y_valid = input_y.iloc[train_idx], input_y.iloc[valid_idx]\n",
    "\n",
    "        model = ExtraTreesRegressor(n_jobs=-1, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_valid)\n",
    "        models.append(model)\n",
    "\n",
    "        oof_pred[valid_idx] = pred\n",
    "        importances += model.feature_importances_\n",
    "\n",
    "        r2_list.append(r2_score(y_valid, pred))\n",
    "        mae_list.append(mean_absolute_error(y_valid, pred))\n",
    "        rmse_list.append(np.sqrt(mean_squared_error(y_valid, pred)))\n",
    "\n",
    "    # 最終モデルを全データで学習\n",
    "    # final_model = ExtraTreesRegressor(n_jobs=-1, random_state=42)\n",
    "    # final_model.fit(input_x, input_y)\n",
    "\n",
    "    metric = {\n",
    "        \"R2\": np.mean(r2_list),\n",
    "        \"MAE\": np.mean(mae_list),\n",
    "        \"RMSE\": np.mean(rmse_list)\n",
    "    }\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": input_x.columns,\n",
    "        \"importance\": importances / n  # 平均\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "    return models, metric, importance_df, oof_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441adc87",
   "metadata": {},
   "source": [
    "# StratifiedKFoldを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c3fab",
   "metadata": {},
   "source": [
    "1. 等幅Bin  \n",
    "2. 等位Bin  \n",
    "Sturges’ Ruleに基づいて、データを分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等幅ビン（Sturges’ Rule 本来の解釈）\n",
    "def compare_linear_models_cv_equal_width(input_x, input_y, seed=42):\n",
    "    N = len(input_y)\n",
    "    k_bins = int(np.floor(np.log2(N) + 1))  # Sturges' Rule\n",
    "\n",
    "    # 等幅ビン分割（cut）\n",
    "    y_bins = pd.cut(input_y, bins=k_bins, labels=False)\n",
    "\n",
    "    # モデル定義\n",
    "    models_to_compare = {\n",
    "        'LinearRegression': lambda: LinearRegression(),\n",
    "        'Ridge': lambda: Ridge(alpha=1.0, random_state=seed),\n",
    "        'Lasso': lambda: Lasso(alpha=0.01, random_state=seed, max_iter=10000),\n",
    "        'PLS': lambda: PLSRegression(n_components=5),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    for model_name, model_func in models_to_compare.items():\n",
    "        r2_scores, mae_scores, rmse_scores = [], [], []\n",
    "\n",
    "        for train_idx, valid_idx in skf.split(input_x, y_bins):\n",
    "            X_train, X_valid = input_x.iloc[train_idx], input_x.iloc[valid_idx]\n",
    "            y_train, y_valid = input_y.iloc[train_idx], input_y.iloc[valid_idx]\n",
    "\n",
    "            # スケーリング\n",
    "            scaler_x = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "            X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "            X_valid_scaled = scaler_x.transform(X_valid)\n",
    "            y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "            # 学習\n",
    "            model = model_func()\n",
    "            model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "            # 予測 & 逆変換\n",
    "            y_pred_scaled = model.predict(X_valid_scaled)\n",
    "            y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "            # 評価\n",
    "            r2_scores.append(r2_score(y_valid, y_pred))\n",
    "            mae_scores.append(mean_absolute_error(y_valid, y_pred))\n",
    "            rmse_scores.append(np.sqrt(mean_squared_error(y_valid, y_pred)))\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"R2\": np.mean(r2_scores),\n",
    "            \"MAE\": np.mean(mae_scores),\n",
    "            \"RMSE\": np.mean(rmse_scores)\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    print(\"=== 等幅ビン (Sturges’ Rule) ===\")\n",
    "    print(result_df)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等分位ビン（実用的：各foldで均等に分割されやすい）\n",
    "def compare_linear_models_cv_equal_freq(input_x, input_y, seed=42):\n",
    "    N = len(input_y)\n",
    "    k_bins = int(np.floor(np.log2(N) + 1))  # Sturges' Rule\n",
    "\n",
    "    # 等分位ビン分割（qcut）\n",
    "    y_bins = pd.qcut(input_y, q=k_bins, labels=False, duplicates=\"drop\")\n",
    "\n",
    "    # モデル定義\n",
    "    models_to_compare = {\n",
    "        'LinearRegression': lambda: LinearRegression(),\n",
    "        'Ridge': lambda: Ridge(alpha=1.0, random_state=seed),\n",
    "        'Lasso': lambda: Lasso(alpha=0.01, random_state=seed, max_iter=10000),\n",
    "        'PLS': lambda: PLSRegression(n_components=5),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    for model_name, model_func in models_to_compare.items():\n",
    "        r2_scores, mae_scores, rmse_scores = [], [], []\n",
    "\n",
    "        for train_idx, valid_idx in skf.split(input_x, y_bins):\n",
    "            X_train, X_valid = input_x.iloc[train_idx], input_x.iloc[valid_idx]\n",
    "            y_train, y_valid = input_y.iloc[train_idx], input_y.iloc[valid_idx]\n",
    "\n",
    "            # スケーリング\n",
    "            scaler_x = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "            X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "            X_valid_scaled = scaler_x.transform(X_valid)\n",
    "            y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "            # 学習\n",
    "            model = model_func()\n",
    "            model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "            # 予測 & 逆変換\n",
    "            y_pred_scaled = model.predict(X_valid_scaled)\n",
    "            y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "            # 評価\n",
    "            r2_scores.append(r2_score(y_valid, y_pred))\n",
    "            mae_scores.append(mean_absolute_error(y_valid, y_pred))\n",
    "            rmse_scores.append(np.sqrt(mean_squared_error(y_valid, y_pred)))\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"R2\": np.mean(r2_scores),\n",
    "            \"MAE\": np.mean(mae_scores),\n",
    "            \"RMSE\": np.mean(rmse_scores)\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    print(\"=== 等分位ビン (Stratified用) ===\")\n",
    "    print(result_df)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55332617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model_function.ipynb to html\n",
      "[NbConvertApp] Writing 327527 bytes to model_function.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html model_function.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
